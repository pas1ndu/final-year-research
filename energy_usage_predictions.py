# -*- coding: utf-8 -*-
"""Energy Usage - Predictions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15t5doMJ8zITxNnxTUXDgvnCWaY1WZiIJ
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
import numpy as np
from sklearn.metrics import r2_score
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files

# Load the dataset from CSV file
data_path = '/content/drive/MyDrive/Final_Data_Set.xlsx'
df = pd.read_excel(data_path)

"""## **Data Exploration and Pre Processing**"""

df.head()

df.info()

df.columns

numeric=['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64', 'object']
elec_dataset_num_and_string=df.select_dtypes(include=numeric)
elec_dataset_num_and_string.head(5)

df.info()

df.shape

df.isna().any()

"""No Null Values

# **Model Training**
"""

# Separate features and target variable
X = df[['Avg Voltage', 'Avg Current', 'Units']]
y = df['Overall Avg Status']

# Encode categorical variables
le = LabelEncoder()
X['Avg Voltage'] = le.fit_transform(X['Avg Voltage'])
X['Avg Current'] = le.fit_transform(X['Avg Current'])
X['Units'] = le.fit_transform(X['Units'])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train and evaluate different classifiers
classifiers = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Logistic Regression': LogisticRegression()
}

for name, classifier in classifiers.items():
    classifier.fit(X_train, y_train)
    y_pred = classifier.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    print(f'{name} Accuracy: {accuracy:.4f}')
    print(f'{name} Precision: {precision:.4f}')
    print(f'{name} Recall: {recall:.4f}')
    print(f'{name} F1 Score: {f1:.4f}')
    print()

# Create a Linear Regression model
regressor = LinearRegression()

"""# Feature Engineering"""

# Feature engineering
df['Mean of Avg Voltage'] = df.groupby('Avg Voltage')['Units'].transform('mean')
df['Mean of Avg Current'] = df.groupby('Avg Current')['Units'].transform('mean')

# Separate features and target variable
X = df[['Avg Voltage', 'Avg Current', 'Units', 'Mean of Avg Voltage', 'Mean of Avg Current']]
y = df['Overall Avg Status']

# Encode categorical variables
le = LabelEncoder()
X['Avg Voltage'] = le.fit_transform(X['Avg Voltage'])
X['Avg Current'] = le.fit_transform(X['Avg Current'])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train and evaluate different classifiers
classifiers = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'Logistic Regression': LogisticRegression()
}

for name, classifier in classifiers.items():
    classifier.fit(X_train, y_train)
    y_pred = classifier.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f'{name} Accuracy: {accuracy:.4f}')

model = RandomForestClassifier()

import pickle
filename = 'Suggestions.pkl'
pickle.dump(model, open(filename,'wb'))

loaded_model = pickle.load(open(filename, 'rb'))

new_data_dict = pd.DataFrame({
    'Avg Voltage': [231.67],
    'Avg Current': [27.12],
    'Units': [1.905],
    'Mean of Avg Voltage': [233.521],
    'Mean of Avg Current': [23.32],
})

# Convert the dictionary to a DataFrame
new_data_df = pd.DataFrame.from_dict(new_data_dict)

# Define the feature names to match those used during training
expected_feature_names = ['Avg Voltage','Avg Current','Units','Mean of Avg Voltage','Mean of Avg Current']

# Set the column names of new_data_df to match the expected feature names
new_data_df.columns = expected_feature_names

loaded_model.fit(X_train, y_train)

# Make predictions using the DataFrame
predictions = loaded_model.predict(new_data_df)

print(predictions)

"""Download File"""

file_path = 'Suggestions.pkl'
files.download(file_path)

"""# Visualizing Data

Pair Plot
"""

# Create a pairplot
sns.pairplot(df, hue='Overall Avg Status', vars=['Avg Voltage', 'Avg Current', 'Units'])
plt.show()

"""Box Plot"""

# Create box plots
plt.figure(figsize=(10, 6))
sns.boxplot(x='Overall Avg Status', y='Avg Voltage', data=df)
plt.title('Box Plot of Avg Voltage by Overall Avg Status')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Overall Avg Status', y='Avg Current', data=df)
plt.title('Box Plot of Avg Current by Overall Avg Status')
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(x='Overall Avg Status', y='Units', data=df)
plt.title('Box Plot of Units by Overall Avg Status')
plt.show()

"""Violin Plot"""

# Create violin plots
plt.figure(figsize=(10, 6))
sns.violinplot(x='Overall Avg Status', y='Avg Voltage', data=df)
plt.title('Violin Plot of Avg Voltage by Overall Avg Status')
plt.show()

plt.figure(figsize=(10, 6))
sns.violinplot(x='Overall Avg Status', y='Avg Current', data=df)
plt.title('Violin Plot of Avg Current by Overall Avg Status')
plt.show()

plt.figure(figsize=(10, 6))
sns.violinplot(x='Overall Avg Status', y='Units', data=df)
plt.title('Violin Plot of Units by Overall Avg Status')
plt.show()

"""Plotting and Checking Distribution of Average Voltage"""

# Get the minimum and maximum values of the 'Avg Voltage' column
min_voltage = df['Avg Voltage'].min()
max_voltage = df['Avg Voltage'].max()

print(f"Minimum Avg Voltage: {min_voltage}")
print(f"Maximum Avg Voltage: {max_voltage}")

df = pd.read_excel('/content/drive/MyDrive/Final_Data_Set.xlsx')

# Calculate quartiles for the 'Avg Voltage' column
quartiles = df['Avg Voltage'].quantile([0.25, 0.5, 0.75])

# Define the threshold values based on quartiles
threshold_low = quartiles[0.25]
threshold_medium = quartiles[0.5]
threshold_high = quartiles[0.75]

# Create a spline chart for Avg Voltage
plt.figure(figsize=(10, 6))
sns.kdeplot(df['Avg Voltage'], color='skyblue', shade=True)
plt.xlabel('Avg Voltage')
plt.ylabel('Density')
plt.title('Spline Chart of Avg Voltage Distribution')

# Add vertical lines at threshold values
plt.axvline(x=threshold_low, color='red', linestyle='--', label='Low Threshold')
plt.axvline(x=threshold_medium, color='green', linestyle='--', label='Medium Threshold')
plt.axvline(x=threshold_high, color='blue', linestyle='--', label='High Threshold')

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend()
plt.show()

# Print the threshold values
print("Low Threshold:", threshold_low)
print("Medium Threshold:", threshold_medium)
print("High Threshold:", threshold_high)

"""Plotting and Checking Distribution of Average Current"""

# Get the minimum and maximum values of the 'Avg Current' column
min_current = df['Avg Current'].min()
max_current = df['Avg Current'].max()

print(f"Minimum Avg Current: {min_current}")
print(f"Maximum Avg Current: {max_current}")

df = pd.read_excel('/content/drive/MyDrive/Final_Data_Set.xlsx')

# Calculate quartiles for the 'Avg Current' column
quartiles = df['Avg Current'].quantile([0.25, 0.5, 0.75])

# Define the threshold values based on quartiles
threshold_low = quartiles[0.25]
threshold_medium = quartiles[0.5]
threshold_high = quartiles[0.75]

# Create a spline chart for Avg Current
plt.figure(figsize=(10, 6))
sns.kdeplot(df['Avg Current'], color='skyblue', shade=True)
plt.xlabel('Avg Current')
plt.ylabel('Density')
plt.title('Spline Chart of Avg Current Distribution')

# Add vertical lines at threshold values
plt.axvline(x=threshold_low, color='red', linestyle='--', label='Low Threshold')
plt.axvline(x=threshold_medium, color='green', linestyle='--', label='Medium Threshold')
plt.axvline(x=threshold_high, color='blue', linestyle='--', label='High Threshold')

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend()
plt.show()

# Print the threshold values
print("Low Threshold:", threshold_low)
print("Medium Threshold:", threshold_medium)
print("High Threshold:", threshold_high)

"""
Plotting and Checking Distribution of Units"""

# Get the minimum and maximum values of the 'Avg Current' column
min_units = df['Units'].min()
max_units = df['Units'].max()

print(f"Minimum Units: {min_units}")
print(f"Maximum Units: {max_units}")

df = pd.read_excel('/content/drive/MyDrive/Final_Data_Set.xlsx')

# Calculate quartiles for the 'Units' column
quartiles = df['Units'].quantile([0.25, 0.5, 0.75])

# Define the threshold values based on quartiles
threshold_low = quartiles[0.25]
threshold_medium = quartiles[0.5]
threshold_high = quartiles[0.75]

# Create a spline chart for Units
plt.figure(figsize=(10, 6))
sns.kdeplot(df['Units'], color='skyblue', shade=True)
plt.xlabel('Units')
plt.ylabel('Density')
plt.title('Spline Chart of Number of Units Distribution')

# Add vertical lines at threshold values
plt.axvline(x=threshold_low, color='red', linestyle='--', label='Low Threshold')
plt.axvline(x=threshold_medium, color='green', linestyle='--', label='Medium Threshold')
plt.axvline(x=threshold_high, color='blue', linestyle='--', label='High Threshold')

plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend()
plt.show()

# Print the threshold values
print("Low Threshold:", threshold_low)
print("Medium Threshold:", threshold_medium)
print("High Threshold:", threshold_high)

# Sample data representing G3, H3, and I3
data = ["High", "Low", "High"]

# Count the number of "High" values in the data
count_high = sum(1 for value in data if value == "High")

# Determine the result based on the count
result = "Overall High" if count_high > 1 else "Average"

print(result)